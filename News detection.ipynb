{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4b9074",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a275a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import re \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce37934",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6006f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(r'C:\\Users\\RezaHardMan\\Documents\\Python projects\\datasets\\news detection\\fake.csv')\n",
    "real_df = pd.read_csv(r'C:\\Users\\RezaHardMan\\Documents\\Python projects\\datasets\\news detection\\True.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68515fa4",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e631ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df.drop(['date', 'subject'], axis=1, inplace=True)\n",
    "real_df.drop(['date', 'subject'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66afd04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df['class'] = 0 \n",
    "real_df['class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c71096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "44893  'Fully committed' NATO backs new U.S. approach...   \n",
       "44894  LexisNexis withdrew two products from Chinese ...   \n",
       "44895  Minsk cultural hub becomes haven from authorities   \n",
       "44896  Vatican upbeat on possibility of Pope Francis ...   \n",
       "44897  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text  class  \n",
       "0      Donald Trump just couldn t wish all Americans ...      0  \n",
       "1      House Intelligence Committee Chairman Devin Nu...      0  \n",
       "2      On Friday, it was revealed that former Milwauk...      0  \n",
       "3      On Christmas day, Donald Trump announced that ...      0  \n",
       "4      Pope Francis used his annual Christmas Day mes...      0  \n",
       "...                                                  ...    ...  \n",
       "44893  BRUSSELS (Reuters) - NATO allies on Tuesday we...      1  \n",
       "44894  LONDON (Reuters) - LexisNexis, a provider of l...      1  \n",
       "44895  MINSK (Reuters) - In the shadow of disused Sov...      1  \n",
       "44896  MOSCOW (Reuters) - Vatican Secretary of State ...      1  \n",
       "44897  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...      1  \n",
       "\n",
       "[44898 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.concat([fake_df, real_df], ignore_index=True, sort=False)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758efe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['text'] = news_df['title'] + news_df['text']\n",
    "news_df.drop('title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b73e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = news_df['text']\n",
    "targets = news_df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.20, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d05df877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't code this part.\n",
    "def normalize(data):\n",
    "    normalized = []\n",
    "    for i in data:\n",
    "        i = i.lower()\n",
    "        # get rid of urls\n",
    "        i = re.sub('https?://\\S+|www\\.\\S+', '', i)\n",
    "        # get rid of non words and extra spaces\n",
    "        i = re.sub('\\\\W', ' ', i)\n",
    "        i = re.sub('\\n', '', i)\n",
    "        i = re.sub(' +', ' ', i)\n",
    "        i = re.sub('^ ', '', i)\n",
    "        i = re.sub(' $', '', i)\n",
    "        normalized.append(i)\n",
    "    return normalized\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a833eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 10000\n",
    "tokenizer = Tokenizer(num_words=max_vocab)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6509854",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fb59050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=256)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=256)\n",
    "# Convert labels to one hot encoding matrix\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2658d",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d177f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_vocab, 32),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=2, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a71270b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 32)          320000    \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, None, 128)        49664     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 32)               18560     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 390,466\n",
      "Trainable params: 390,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "filepath1=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filepath2 = \"best_weights.hdf5\"\n",
    "checkpoint1 = ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint1,checkpoint2]\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb708b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2021/2021 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9090\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98357, saving model to weights-improvement-01-0.98.hdf5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98357, saving model to best_weights.hdf5\n",
      "2021/2021 [==============================] - 72s 33ms/step - loss: 0.2062 - accuracy: 0.9090 - val_loss: 0.0548 - val_accuracy: 0.9836\n",
      "Epoch 2/10\n",
      "2020/2021 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9887\n",
      "Epoch 00002: val_accuracy improved from 0.98357 to 0.99053, saving model to weights-improvement-02-0.99.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.98357 to 0.99053, saving model to best_weights.hdf5\n",
      "2021/2021 [==============================] - 66s 33ms/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 0.0326 - val_accuracy: 0.9905\n",
      "Epoch 3/10\n",
      "2021/2021 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9944\n",
      "Epoch 00003: val_accuracy did not improve from 0.99053\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.99053\n",
      "2021/2021 [==============================] - 66s 32ms/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 0.0402 - val_accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "2021/2021 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9972\n",
      "Epoch 00004: val_accuracy improved from 0.99053 to 0.99193, saving model to weights-improvement-04-0.99.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.99053 to 0.99193, saving model to best_weights.hdf5\n",
      "2021/2021 [==============================] - 66s 33ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.0334 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "2021/2021 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9981 ETA: 0s - l\n",
      "Epoch 00005: val_accuracy did not improve from 0.99193\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99193\n",
      "2021/2021 [==============================] - 66s 33ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0352 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "2021/2021 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 00006: val_accuracy did not improve from 0.99193\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99193\n",
      "2021/2021 [==============================] - 68s 33ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0418 - val_accuracy: 0.9911\n",
      "Epoch 7/10\n",
      "2020/2021 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 00007: val_accuracy improved from 0.99193 to 0.99415, saving model to weights-improvement-07-0.99.hdf5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99193 to 0.99415, saving model to best_weights.hdf5\n",
      "2021/2021 [==============================] - 69s 34ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0353 - val_accuracy: 0.9942\n",
      "Epoch 8/10\n",
      "2020/2021 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 00008: val_accuracy did not improve from 0.99415\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99415\n",
      "2021/2021 [==============================] - 68s 34ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0449 - val_accuracy: 0.9916\n",
      "Epoch 9/10\n",
      "2021/2021 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00009: val_accuracy did not improve from 0.99415\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99415\n",
      "2021/2021 [==============================] - 69s 34ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0363 - val_accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "2021/2021 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 00010: val_accuracy did not improve from 0.99415\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99415\n",
      "2021/2021 [==============================] - 68s 34ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0441 - val_accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=16, validation_split=0.1, epochs = 10, verbose=1, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03c9375",
   "metadata": {},
   "source": [
    "## Testing model on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4486126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 6s 22ms/step - loss: 0.0442 - accuracy: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04422454163432121, 0.9924275875091553]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1458e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very well :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
